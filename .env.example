# Model can be found from https://python.langchain.com/v0.2/docs/integrations/chat/nvidia_ai_endpoints/#supported-models
MODEL = "meta/codellama-70b"
# The maximum tokens that the output will have
MAX_TOKENS = 200
# Temperature on the range of [0, 1], ideally kept to one as a way of ensuring that things aren't accidently run
TEMPERATURE = 0
# Whether you want to confirm before running the command, or just run the command without checking
CHECK = TRUE
# NVIDIA_API_KEY can be found using: https://python.langchain.com/v0.2/docs/integrations/chat/nvidia_ai_endpoints/#setup
# Make sure to not make this publicly exposed
NVIDIA_API_KEY = ""
